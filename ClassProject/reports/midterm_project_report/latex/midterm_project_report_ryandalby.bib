
@article{hancock_survey_2020,
	title = {Survey on categorical data for neural networks},
	volume = {7},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-020-00305-w},
	doi = {10.1186/s40537-020-00305-w},
	abstract = {This survey investigates current techniques for representing qualitative data for use as input to neural networks. Techniques for using qualitative data in neural networks are well known. However, researchers continue to discover new variations or entirely new methods for working with categorical data in neural networks. Our primary contribution is to cover these representation techniques in a single work. Practitioners working with big data often have a need to encode categorical values in their datasets in order to leverage machine learning algorithms. Moreover, the size of data sets we consider as big data may cause one to reject some encoding techniques as impractical, due to their running time complexity. Neural networks take vectors of real numbers as inputs. One must use a technique to map qualitative values to numerical values before using them as input to a neural network. These techniques are known as embeddings, encodings, representations, or distributed representations. Another contribution this work makes is to provide references for the source code of various techniques, where we are able to verify the authenticity of the source code. We cover recent research in several domains where researchers use categorical data in neural networks. Some of these domains are natural language processing, fraud detection, and clinical document automation. This study provides a starting point for research in determining which techniques for preparing qualitative data for use with neural networks are best. It is our intention that the reader should use these implementations as a starting point to design experiments to evaluate various techniques for working with qualitative data in neural networks. The third contribution we make in this work is a new perspective on techniques for using categorical data in neural networks. We organize techniques for using categorical data in neural networks into three categories. We find three distinct patterns in techniques that identify a technique as determined, algorithmic, or automated. The fourth contribution we make is to identify several opportunities for future research. The form of the data that one uses as an input to a neural network is crucial for using neural networks effectively. This work is a tool for researchers to find the most effective technique for working with categorical data in neural networks, in big data settings. To the best of our knowledge this is the first in-depth look at techniques for working with categorical data in neural networks.},
	number = {1},
	urldate = {2021-10-24},
	journal = {Journal of Big Data},
	author = {Hancock, John T. and Khoshgoftaar, Taghi M.},
	month = apr,
	year = {2020},
	keywords = {Big data, Deep learning, Embedding, Encoding, ml\_mid\_proj, Neural networks, Qualitative data},
	pages = {28},
	file = {Full Text PDF:/Users/dalbyryan3/Documents/school/research/zotero/storage/6HQBBHDW/Hancock and Khoshgoftaar - 2020 - Survey on categorical data for neural networks.pdf:application/pdf;Snapshot:/Users/dalbyryan3/Documents/school/research/zotero/storage/NLXXECP6/s40537-020-00305-w.html:text/html},
}

@article{ng_advice_nodate,
	title = {Advice for applying {Machine} {Learning}},
	language = {en},
	author = {Ng, Andrew},
	keywords = {ml\_mid\_proj},
	pages = {30},
	file = {Ng - Advice for applying Machine Learning.pdf:/Users/dalbyryan3/Documents/school/research/zotero/storage/66HKG25A/Ng - Advice for applying Machine Learning.pdf:application/pdf},
}

@misc{noauthor_11_nodate,
	title = {1.1. {Linear} {Models}},
	url = {https://scikit-learn/stable/modules/linear_model.html},
	abstract = {The following are a set of methods intended for regression in which the target value is expected to be a linear combination of the features. In mathematical notation, if{\textbackslash}hat\{y\} is the predicted val...},
	language = {en},
	urldate = {2021-10-25},
	journal = {scikit-learn},
	keywords = {ml\_mid\_proj},
	file = {Snapshot:/Users/dalbyryan3/Documents/school/research/zotero/storage/KKX63X2R/linear_model.html:text/html},
}

@misc{noauthor_14_nodate,
	title = {1.4. {Support} {Vector} {Machines}},
	url = {https://scikit-learn/stable/modules/svm.html},
	abstract = {Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection. The advantages of support vector machines are: Effective in high ...},
	language = {en},
	urldate = {2021-10-25},
	journal = {scikit-learn},
	keywords = {ml\_mid\_proj},
	file = {Snapshot:/Users/dalbyryan3/Documents/school/research/zotero/storage/CIVZFBKV/svm.html:text/html},
}

@misc{noauthor_scikit-learn_nodate,
	title = {scikit-learn: machine learning in {Python} — scikit-learn 1.0 documentation},
	url = {https://scikit-learn.org/stable/},
	urldate = {2021-10-25},
	keywords = {ml\_mid\_proj},
	file = {scikit-learn\: machine learning in Python — scikit-learn 1.0 documentation:/Users/dalbyryan3/Documents/school/research/zotero/storage/KV9QLRZV/stable.html:text/html},
}

@misc{noauthor_111_nodate,
	title = {1.11. {Ensemble} methods},
	url = {https://scikit-learn/stable/modules/ensemble.html},
	abstract = {The goal of ensemble methods is to combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator...},
	language = {en},
	urldate = {2021-10-25},
	journal = {scikit-learn},
	keywords = {ml\_mid\_proj},
	file = {Snapshot:/Users/dalbyryan3/Documents/school/research/zotero/storage/8N69F73I/ensemble.html:text/html},
}
